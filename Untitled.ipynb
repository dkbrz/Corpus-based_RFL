{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docx2txt.process(\"./texts/(2-3).docx\")\n",
    "text = ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 – 3 года Киска, киска, киска, брысь! На дорожку не садись. Наша деточка пойдет, Через киску упадет! Ты, собачка, не лай, Наших уток не пугай! Утки наши белые Без того несмелые. Ой, ду-ду, ду-ду, ду-'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pymystem3.Mystem(disambiguation=True, weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "?m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': '2'},\n",
       " {'text': ' – '},\n",
       " {'text': '3'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'год', 'gr': 'S,муж,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'года'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'киска', 'gr': 'S,жен,од=им,ед'}], 'text': 'Киска'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'lex': 'киска', 'gr': 'S,жен,од=им,ед'}], 'text': 'киска'},\n",
       " {'text': ', '}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.analyze(text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "analized = [x for x in m.analyze(text) if 'analysis' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'год', 'gr': 'S,муж,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'года'},\n",
       " {'analysis': [{'lex': 'киска', 'gr': 'S,жен,од=им,ед'}], 'text': 'Киска'},\n",
       " {'analysis': [{'lex': 'киска', 'gr': 'S,жен,од=им,ед'}], 'text': 'киска'},\n",
       " {'analysis': [{'lex': 'киска', 'gr': 'S,жен,од=им,ед'}], 'text': 'киска'},\n",
       " {'analysis': [{'lex': 'брысь', 'gr': 'INTJ='}], 'text': 'брысь'},\n",
       " {'analysis': [{'lex': 'на', 'gr': 'PR='}], 'text': 'На'},\n",
       " {'analysis': [{'lex': 'дорожка', 'gr': 'S,жен,неод=вин,ед'}],\n",
       "  'text': 'дорожку'},\n",
       " {'analysis': [{'lex': 'не', 'gr': 'PART='}], 'text': 'не'},\n",
       " {'analysis': [{'lex': 'садиться',\n",
       "    'gr': 'V,нп=(ед,пов,2-л,несов|ед,пов,2-л,сов)'}],\n",
       "  'text': 'садись'},\n",
       " {'analysis': [{'lex': 'наш', 'gr': 'APRO=им,ед,жен'}], 'text': 'Наша'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = morph.parse('топ')[0]\n",
    "word.inflect({'plur'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='ребятишки', tag=OpencorporaTag('NOUN,anim,GNdr,Pltm plur,nomn'), normal_form='ребятишки', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'ребятишки', 1275, 0),))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('ребятишки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declension(word_object):\n",
    "    gr = word_object['gr']\n",
    "    lex = word_object['lex']\n",
    "    if len(gr.split('|')) > 10:\n",
    "        return ('Н')\n",
    "    elif 'муж' in gr:\n",
    "        if re.match('.*[^аёиуэюяй]$', lex) or re.match('.*[^оиы]й$', lex):\n",
    "            if lex in ['путь', 'пламень']: return 'Р'\n",
    "            else: return '2'\n",
    "        elif re.match('.*[^а][ая]$', lex): return '1'\n",
    "        elif re.match('.*[оыи]й(ся)?$', lex):\n",
    "            word = morph.parse(lex)\n",
    "            n = None\n",
    "            for key, value in enumerate(word):\n",
    "                if 'masc' in value.tag and value.inflect({'gent', 'sing'}):\n",
    "                    n = key\n",
    "                    break\n",
    "            if n is not None:\n",
    "                if re.match('.*го(ся)?$', word[n].inflect({'gent','sing'}).word): return 'А'\n",
    "                else: return '2'\n",
    "    elif 'жен' in gr:\n",
    "        if re.match('.*[^а][ая]$', lex): return '1'\n",
    "        elif re.match('.*ь$', lex): return '3'\n",
    "        elif re.match('.*(ая|яя)$(ся)?', lex):\n",
    "            word = morph.parse(lex)\n",
    "            n = None\n",
    "            for key, value in enumerate(word):\n",
    "                if 'femn' in value.tag and value.inflect({'gent', 'sing'}):\n",
    "                    n = key\n",
    "                    break\n",
    "            if n is not None:\n",
    "                if re.match('.*[ое]й(ся)?$', word[n].inflect({'gent','sing'}).word): return 'А'\n",
    "                else: return '1'\n",
    "    elif 'сред' in gr:\n",
    "        if re.match('.*[^о][ое]$', lex): return '2'\n",
    "        elif re.match('.*мя$', lex): return 'Р'\n",
    "        elif re.match('.*ое$(ся)?', lex): return 'А'\n",
    "        elif lex in ['дитя']: return 'Р'\n",
    "    elif 'мж' in gr:\n",
    "        return '1'\n",
    "    elif 'мн' in gr:\n",
    "        return ('T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='стая', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='стая', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'стая', 233, 0),))]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('стая')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_all_texts('./texts/')\n",
    "declension_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Р\n"
     ]
    }
   ],
   "source": [
    "lex = 'пламень'\n",
    "if re.match('.*[^аёиуэюяй]$', lex) or re.match('.*[^оиы]й$', lex):\n",
    "    if lex in ['путь', 'пламень']: print('Р')\n",
    "    else: print ('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis': [{'lex': 'пламень', 'gr': 'S,неод=(им,ед,муж|вин,ед,муж)'}],\n",
       " 'text': 'пламень'}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'пламень'\n",
    "m.analyze(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'муж' in m.analyze(text)[0]['analysis'][0]['gr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "analized = [x for x in m.analyze(text) if 'analysis' in x]\n",
    "declension(m.analyze(text)[0]['analysis'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general(array):\n",
    "    for i in array:\n",
    "        if i['analysis']:\n",
    "            if 'S,' in i['analysis'][0]['gr']:\n",
    "                print (declension(i['analysis'][0]), i['analysis'][0]['lex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ква'\n",
    "analized = [x for x in m.analyze(text) if 'analysis' in x]\n",
    "general(analized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "А служащий\n",
      "1 гостиница\n",
      "1 вредина\n",
      "Н киви\n",
      "2 кай\n",
      "1 мужчина\n"
     ]
    }
   ],
   "source": [
    "text = 'Служащий гостиницы - большой вредина и киви Кай и мужчина'\n",
    "analized = [x for x in m.analyze(text) if 'analysis' in x]\n",
    "general(analized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'ребятишки', 'gr': 'S,мн,од=им'}], 'text': 'ребятишки'},\n",
       " {'text': '\\n'}]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.analyze('ребятишки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2  –  3   год   киска ,  киска ,  киска ,  брысь !  на   дорожка   не   садиться .  наш   деточка   пойти ,  через   киска   упасть !  ты ,  собачка ,  не   лаять ,  наш   утка   не   пугать !  утка   наш   белый   без   то   несмелый .  ой ,  ду - ду ,  ду - ду ,  ду - ду …  потерять   пастух   дуд'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time ' '.join(m.lemmatize(text))[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_declension(array):\n",
    "    for i in array:\n",
    "        if i['analysis']:\n",
    "            if 'S,' in i['analysis'][0]['gr']:\n",
    "                yield declension(i['analysis'][0]), i['analysis'][0]['lex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_texts(path):\n",
    "    result = defaultdict(lambda: [None, 0])\n",
    "    for root, dirs, files in os.walk (path):\n",
    "        for file in files:\n",
    "            text = docx2txt.process(root+'/'+file)\n",
    "            text = ' '.join(text.split())\n",
    "            analized = [x for x in m.analyze(text) if 'analysis' in x]\n",
    "            for dec, lemma in text_declension(analized):\n",
    "                result[lemma][0] = dec\n",
    "                result[lemma][1] += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_result(result):\n",
    "    result2 = defaultdict(list)\n",
    "    for key in sorted(result):\n",
    "        result2[result[key][0]].append((key, result[key][1]))\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='рои', tag=OpencorporaTag('NOUN,anim,masc,Name plur,nomn'), normal_form='рой', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'рои', 41, 6),))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = morph.parse('рой')[0]\n",
    "word.inflect({'plur', 'nomn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='дорогой', tag=OpencorporaTag('ADVB'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 3, 0),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('NOUN,inan,femn sing,ablt'), normal_form='дорога', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 43, 4),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual masc,sing,nomn'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 0),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual inan,masc,sing,accs'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 4),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual femn,sing,gent'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 8),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual femn,sing,datv'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 9),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual femn,sing,ablt'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 11),)),\n",
       " Parse(word='дорогой', tag=OpencorporaTag('ADJF,Qual femn,sing,loct'), normal_form='дорогой', score=0.125, methods_stack=((<DictionaryAnalyzer>, 'дорогой', 1327, 13),))]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse('дорогой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Р'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "declension(m.analyze(text)[0]['analysis'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_all_texts('./texts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 4]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['пламень']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declension_results(result, file):\n",
    "    S = sorted_result(result)\n",
    "    for key in S:\n",
    "        print (key, '\\n')\n",
    "        for word, n in sorted(S[key], key=lambda x: (x[1], x[0]), reverse=True):\n",
    "               print (word, '\\t', n)\n",
    "        print ('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None \n",
      "\n",
      "дитя \t 39\n",
      "ученый \t 14\n",
      "толстой \t 8\n",
      "пожарный \t 8\n",
      "чуковский \t 7\n",
      "подданный \t 7\n",
      "постовой \t 6\n",
      "пляцковский \t 4\n",
      "пламень \t 4\n",
      "больной \t 4\n",
      "бой \t 4\n",
      "строй \t 3\n",
      "полчаса \t 3\n",
      "малый \t 3\n",
      "китобой \t 3\n",
      "голодный \t 3\n",
      "вой \t 3\n",
      "взрослый \t 3\n",
      "белый \t 3\n",
      "бедный \t 3\n",
      "черный \t 2\n",
      "часовой \t 2\n",
      "суженый \t 2\n",
      "прохожий \t 2\n",
      "портной \t 2\n",
      "полицейский \t 2\n",
      "мертвый \t 2\n",
      "косой \t 2\n",
      "знакомый \t 2\n",
      "вожатый \t 2\n",
      "хмельницкий \t 1\n",
      "флотский \t 1\n",
      "тульский \t 1\n",
      "старший \t 1\n",
      "слой \t 1\n",
      "скребицкий \t 1\n",
      "святой \t 1\n",
      "рядовой \t 1\n",
      "рой \t 1\n",
      "рался \t 1\n",
      "пропой \t 1\n",
      "постой \t 1\n",
      "постненький \t 1\n",
      "полушаги \t 1\n",
      "полстакана \t 1\n",
      "полпути \t 1\n",
      "полбанки \t 1\n",
      "покровский \t 1\n",
      "покой \t 1\n",
      "отеу \t 1\n",
      "одоевский \t 1\n",
      "нищий \t 1\n",
      "нинок \t 1\n",
      "нечистый \t 1\n",
      "несчастный \t 1\n",
      "мастеровой \t 1\n",
      "маленький \t 1\n",
      "любопытный \t 1\n",
      "леонтий \t 1\n",
      "краснолапый \t 1\n",
      "котобой \t 1\n",
      "коренной \t 1\n",
      "ирок \t 1\n",
      "игнаток \t 1\n",
      "зной \t 1\n",
      "зинок \t 1\n",
      "дорогой \t 1\n",
      "дежурный \t 1\n",
      "дворовый \t 1\n",
      "дворецкий \t 1\n",
      "гравий \t 1\n",
      "горбовский \t 1\n",
      "выходной \t 1\n",
      "водопой \t 1\n",
      "введенский \t 1\n",
      "василий \t 1\n",
      "ближний \t 1\n",
      "барабани \t 1\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = get_all_texts('./texts/')\n",
    "declension_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_declension(path, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as output:\n",
    "        result = get_all_texts(path)\n",
    "        S = sorted_result(result)\n",
    "        for key in sorted(S.keys(), key=str):\n",
    "            for word, n in sorted(S[key], key=lambda x: (x[1], x[0]), reverse=True):\n",
    "                s = '{}\\t{}\\t{}\\n'.format(str(key), str(word), str(n))\n",
    "                output.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%time stats_declension('./texts/', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import win32com.client as win32\n",
    "from win32com.client import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate ()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "\n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "\n",
    "def find_docs(path):\n",
    "    for root, dirs, files in os.walk (path):\n",
    "        for file in files:\n",
    "            if file[-4:] == '.doc':\n",
    "                filename = os.path.abspath(root+'/'+file)\n",
    "                save_as_docx(filename)\n",
    "                os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_docs('./texts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разные форматы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename, mode):\n",
    "    if mode == 'txt':\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    elif mode == 'docx':\n",
    "        text = docx2txt.process(filename)\n",
    "        return text\n",
    "    else: print ('Error: '+ mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_texts(path):\n",
    "    find_docs(path)\n",
    "    for root, dirs, files in os.walk (path):\n",
    "        for file in files:\n",
    "            mode = file.split('.')[-1]\n",
    "            text = get_text(os.path.abspath(root+'/'+file), mode)\n",
    "            #print (text[:100])\n",
    "            yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2-3).docx\n",
      "(3-4).docx\n",
      "(4-5).docx\n",
      "(5-6).docx\n",
      "(6-7).docx\n",
      "lkjlj.txt\n"
     ]
    }
   ],
   "source": [
    "get_all_texts('./texts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_text(text):\n",
    "    text = ' '.join(text.split())\n",
    "    analized = [x['analysis'][0] for x in m.analyze(text) if 'analysis' in x and x['analysis']]\n",
    "    result = defaultdict(lambda: [0, ''])\n",
    "    for i in analized:\n",
    "        lex = i['lex']\n",
    "        pos = i['gr'].split('=')[0].split(',')[0]\n",
    "        result[(lex, pos)][0] += 1\n",
    "        if pos == 'S':\n",
    "            result[(lex, pos)][1] = declension(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_text_lex_stats(path):\n",
    "    result = defaultdict(lambda: [0, ''])\n",
    "    for text in get_all_texts(path):\n",
    "        current = one_text(text)\n",
    "        for key in current:\n",
    "            result[key][0] += current[key][0]\n",
    "            result[key][1] = current[key][1]\n",
    "    with open ('frequency_list.txt','w',encoding='utf-8') as output:\n",
    "        output.write('lemma\\tPOS\\tfreq\\tdeclension\\n')\n",
    "        for key in sorted(result, key=lambda x: result[x][0], reverse=True):\n",
    "            s = '{}\\t{}\\n'.format(str('\\t'.join(key)), str('\\t'.join(str(i) for i in result[key])))\n",
    "            output.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'абак':['S', 1, '2'], 'бабушка':['S', 10, '', '1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абак\tS\t1\t2\n",
      "\n",
      "бабушка\tS\t10\t\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(result, key=lambda x: x[1], reverse=True):\n",
    "    print('{}\\t{}\\n'.format(str(key), str('\\t'.join(str(i) for i in result[key]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%time all_text_lex_stats('./texts/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
